{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport json\nimport os\nimport wandb\nimport random\nimport itertools\nimport gc\nfrom huggingface_hub import whoami, login\nfrom datasets import load_dataset\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom collections import Counter, defaultdict\nfrom PIL import Image\nimport torchvision.transforms as T\nfrom google.colab import userdata\nfrom datetime import datetime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:17:29.844077Z","iopub.execute_input":"2025-10-19T13:17:29.844626Z","iopub.status.idle":"2025-10-19T13:17:42.701364Z","shell.execute_reply.started":"2025-10-19T13:17:29.844599Z","shell.execute_reply":"2025-10-19T13:17:42.700786Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# CIDEr-D implementation (simplified)\ndef cider_d(candidates, mult_references, n=4, sigma=6.0, scale=10.0):\n    from collections import Counter\n    import numpy as np\n\n    def __cook_sentence(sentence, n):\n        tokens = sentence.split()\n        return Counter(tuple(tokens[i:i + k]) for k in range(1, n + 1) for i in range(len(tokens) - k + 1))\n\n    def __compute_doc_freq(cooked_mrefs):\n        doc_freq = Counter()\n        for refs in cooked_mrefs:\n            ngram_set = set()\n            for ref in refs:\n                ngram_set.update(ref.keys())\n            doc_freq.update(ngram_set)\n        return doc_freq\n\n    cooked_mrefs = [[__cook_sentence(ref, n) for ref in refs] for refs in mult_references]\n    cooked_cands = [__cook_sentence(cand, n) for cand in candidates]\n    doc_frequencies = __compute_doc_freq(cooked_mrefs)\n    log_n_refs = np.log(float(len(cooked_mrefs)))\n\n    scores = []\n    for cand, refs in zip(cooked_cands, cooked_mrefs):\n        cand_vec = [Counter() for _ in range(n)]\n        cand_norm = [0.0] * n\n        cand_len = sum(cand[t] for t in cand if len(t) == 1)\n        for ngram, freq in cand.items():\n            k = len(ngram) - 1\n            df = doc_frequencies.get(ngram, 0)\n            idf = log_n_refs - np.log(max(1, df))\n            cand_vec[k][ngram] = freq * idf\n            cand_norm[k] += (freq * idf) ** 2\n        cand_norm = [np.sqrt(no) for no in cand_norm]\n\n        ngrams_scores = []\n        for ref in refs:\n            ref_vec = [Counter() for _ in range(n)]\n            ref_norm = [0.0] * n\n            ref_len = sum(ref[t] for t in ref if len(t) == 1)\n            for ngram, freq in ref.items():\n                k = len(ngram) - 1\n                df = doc_frequencies.get(ngram, 0)\n                idf = log_n_refs - np.log(max(1, df))\n                ref_vec[k][ngram] = freq * idf\n                ref_norm[k] += (freq * idf) ** 2\n            ref_norm = [np.sqrt(no) for no in ref_norm]\n\n            sims = []\n            for ni in range(n):\n                sim = 0\n                for ngram, count in cand_vec[ni].items():\n                    sim += min(count, ref_vec[ni].get(ngram, 0)) * ref_vec[ni].get(ngram, 0)\n                if cand_norm[ni] != 0 and ref_norm[ni] != 0:\n                    sim /= cand_norm[ni] * ref_norm[ni]\n                sim *= np.exp(-((cand_len - ref_len) ** 2) / (2 * sigma ** 2))\n                sims.append(sim)\n            ngrams_scores.append(sum(sims) / n)\n        scores.append(sum(ngrams_scores) / len(ngrams_scores))\n    scores = np.array(scores) * scale\n    return {\"cider_d\": float(scores.mean())}, {\"cider_d\": torch.tensor(scores)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:17:49.005996Z","iopub.execute_input":"2025-10-19T13:17:49.006693Z","iopub.status.idle":"2025-10-19T13:17:49.018046Z","shell.execute_reply.started":"2025-10-19T13:17:49.006665Z","shell.execute_reply":"2025-10-19T13:17:49.017305Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"## Using Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nwandb_key = user_secrets.get_secret(\"wandb_api_key\")\n\nif not hf_token or not wandb_key:\n    raise ValueError(\"HF_TOKEN or wandb_key not found in Colab secrets.\")\n\n## Authentication\nlogin(hf_token)\nwandb.login(key= wandb_key)\n\nos.environ[\"HF_TOKEN\"] = hf_token\nos.environ[\"WANDB_PROJECT\"] = \"Kvasir-VQA-x1_Subtask1\"\nos.environ[\"WANDB_WATCH\"] = \"all\"\nos.environ[\"WANDB_DISABLED\"] = \"false\"\nos.environ[\"WANDB_LOG_MODEL\"] = \"false\"\n\n# Test\nHF_USER = whoami()[\"name\"]\nprint(\"Logged into HF as:\", HF_USER)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:17:51.977605Z","iopub.execute_input":"2025-10-19T13:17:51.977863Z","iopub.status.idle":"2025-10-19T13:17:59.467441Z","shell.execute_reply.started":"2025-10-19T13:17:51.977844Z","shell.execute_reply":"2025-10-19T13:17:59.466830Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfirojpaudel\u001b[0m (\u001b[33mfirojpaudel-madan-bhandari-memorial-college\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"Logged into HF as: Firoj112\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Data Preparation\n\"\"\"\nWhat we will do:\n1) Cache images locally from SimulaMet-HOST/Kvasir-VQA with augmentation\n2) Build VLM-ready JSONL files for train/test splits\n3) Inspect dataset balance by question type\n\"\"\"\n\n# Working directories\nBASE_DIR = Path(\"./\")\nDATA_DIR = BASE_DIR / \"Kvasir-VQA-x1\"\nIMG_DIR = DATA_DIR / \"images\"\nDATA_DIR.mkdir(parents=True, exist_ok=True)\nIMG_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Data dir:\", DATA_DIR)\nprint(\"Images dir:\", IMG_DIR)\n\n# Augment Function\ndef augment_image(img):\n    \"\"\"Apply data augmentation to PIL image\"\"\"\n    transform = T.Compose([\n        T.RandomRotation(15),\n        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        T.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n        T.RandomHorizontalFlip(),\n    ])\n    return transform(img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:17:59.468531Z","iopub.execute_input":"2025-10-19T13:17:59.469195Z","iopub.status.idle":"2025-10-19T13:17:59.474973Z","shell.execute_reply.started":"2025-10-19T13:17:59.469152Z","shell.execute_reply":"2025-10-19T13:17:59.474313Z"}},"outputs":[{"name":"stdout","text":"Data dir: Kvasir-VQA-x1\nImages dir: Kvasir-VQA-x1/images\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# 1. Saving unique images locally with optional augmentation\nprint(\"⏬ Caching images from SimulaMet-HOST/Kvasir-VQA ...\")\nhost = load_dataset(\"SimulaMet-HOST/Kvasir-VQA\", split=\"raw\")\ndf = host.select_columns(['source', 'question', 'answer', 'img_id']).to_pandas()\n# Save one image per unique img_id\nfor i, row in tqdm(df.groupby('img_id').nth(0).iterrows(), total=df['img_id'].nunique()):\n    p = IMG_DIR / f\"{row['img_id']}.jpg\"\n    if p.exists():\n        continue\n    host[i]['image'].save(p)\n\n# 2. Create JSONLs for train/test from Kvasir-VQA-x1 (VLM-ready for ms-swift)\nprint(\"Creating JSONLs ...\")\ndef write_jsonl(split):\n    out_path = DATA_DIR / f\"Kvasir-VQA-x1-{split}.jsonl\"\n    ds = load_dataset(\"SimulaMet/Kvasir-VQA-x1\", split=split)\n    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n        for r in ds:\n            rec = {\n                \"messages\": [\n                    {\"role\": \"user\", \"content\": f\"<image>{r['question']}\"},\n                    {\"role\": \"assistant\", \"content\": r[\"answer\"]}\n                ],\n                \"images\": [str(IMG_DIR / f\"{r['img_id']}.jpg\")]\n            }\n            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n    return out_path\n\ntrain_jsonl = write_jsonl(\"train\")\ntest_jsonl = write_jsonl(\"test\")\n\nprint(\"Train JSONL:\", train_jsonl)\nprint(\"Test JSONL:\", test_jsonl)\n\nsample_lines = list(itertools.islice(open(train_jsonl, \"r\", encoding=\"utf-8\"), 3))\nfor i, line in enumerate(sample_lines, 1):\n    j = json.loads(line)\n    print(f\"\\n--- Sample {i} ---\")\n    print(\"messages:\", j[\"messages\"])\n    print(\"images:\", j[\"images\"])\n    assert Path(j[\"images\"][0]).exists(), \"Missing image file!\"\nprint(\"\\nLooks good ✅\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:18:04.155853Z","iopub.execute_input":"2025-10-19T13:18:04.156130Z","iopub.status.idle":"2025-10-19T13:20:44.176561Z","shell.execute_reply.started":"2025-10-19T13:18:04.156108Z","shell.execute_reply":"2025-10-19T13:20:44.175788Z"}},"outputs":[{"name":"stdout","text":"⏬ Caching images from SimulaMet-HOST/Kvasir-VQA ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d56eb5c38d4734aa0c5aa224fa5050"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"532657d6a66843d0aeab6b5f5f3070b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221ac04fcdaf445195ec500271c3bb7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/31 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93792e7c69a842e29a6acd22bb68ef0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00000.parquet:   0%|          | 0.00/26.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49184e78f2af43259486b5ce20f3a7c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00001.parquet:   0%|          | 0.00/26.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60a9d4284cbc4d68bf9308c464dc0151"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00002.parquet:   0%|          | 0.00/25.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc91d65bbd0d47bc8b915db312feb1d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00003.parquet:   0%|          | 0.00/18.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"917ab8eca8b74c038d349bf0eb74e7ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00004.parquet:   0%|          | 0.00/22.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3c7b60ef7e54878b0239e6aca679aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00005.parquet:   0%|          | 0.00/23.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7b419552ca4c6782d2e7ee2f2e5a07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00006.parquet:   0%|          | 0.00/21.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e166287f773d48d69b24e758b0590816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00007.parquet:   0%|          | 0.00/23.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa2175d418c442ab89fa714e4276d87a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00008.parquet:   0%|          | 0.00/20.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eda4695f2094fc9a8e9ebaa91e0a9ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00009.parquet:   0%|          | 0.00/5.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab512051a2446ada9a418b08b2df764"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00010.parquet:   0%|          | 0.00/5.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"343221110eac4b49b45527d0c3da0474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00011.parquet:   0%|          | 0.00/8.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b00fa0394f4b9a978929df22929989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00012.parquet:   0%|          | 0.00/6.49M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dfde6f0b420412b8ee4cd1e5777624b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00013.parquet:   0%|          | 0.00/6.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10b33d4dddfa4dd9b1dcb827279658a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00014.parquet:   0%|          | 0.00/5.89M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1552d92aac664a3a9b018ea55f57b952"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00015.parquet:   0%|          | 0.00/4.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fca96552cf6345c4a9381e7df1f154a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00016.parquet:   0%|          | 0.00/64.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f58de6aa5ead48579e938e82b524f275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00017.parquet:   0%|          | 0.00/67.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60d9c81aee2b490184fa71106b69134c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00018.parquet:   0%|          | 0.00/68.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"480daab0c7f34cbabcd0d81b88a1f9df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00019.parquet:   0%|          | 0.00/67.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98971aa43124835bba74e6ac21664bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00020.parquet:   0%|          | 0.00/66.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ac3cd0b6c2443dabdc28b402fac364"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00021.parquet:   0%|          | 0.00/68.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b370f9dc794bf8bd2026c83120138d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00022.parquet:   0%|          | 0.00/72.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69f8fb4f60e64af8b7e26f80c64094a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00023.parquet:   0%|          | 0.00/72.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bf437a6853c4fa4a13cfac38e391d1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00024.parquet:   0%|          | 0.00/111M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d71eacf26c44df8f4644675a8ea832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00025.parquet:   0%|          | 0.00/305M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f63e48ac44742a68b948e35dec6790b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00026.parquet:   0%|          | 0.00/87.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84867525cc2b4c0f850dc8014d7cd282"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00027.parquet:   0%|          | 0.00/42.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fca1a0334494c64855ab348fb82dc34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00028.parquet:   0%|          | 0.00/73.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00ad8929ec24521a2c077f7ed964b51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00029.parquet:   0%|          | 0.00/60.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3d15aad1c954b6f8958986e1c2bb8eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/00030.parquet:   0%|          | 0.00/67.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aebd826b1c44cfb8244efb4f8078efe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating raw split:   0%|          | 0/58849 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"034a9f4d50224e65afb3bdf4529fde05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61bdd125b55944f1a47c18cf09fcb462"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 6500/6500 [00:53<00:00, 121.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Creating JSONLs ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5889d3aba154079a435e54e511c7ce1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/14.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d468bef241648089e4330b68a936af4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/1.65M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f7e198f3a8481d86101d1a867ebd85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/143594 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bcae092836c40a5a6857cf66804061e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/15955 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d653a9771d40dca2dfe762a21e0540"}},"metadata":{}},{"name":"stdout","text":"Train JSONL: Kvasir-VQA-x1/Kvasir-VQA-x1-train.jsonl\nTest JSONL: Kvasir-VQA-x1/Kvasir-VQA-x1-test.jsonl\n\n--- Sample 1 ---\nmessages: [{'role': 'user', 'content': '<image>Are there any abnormalities, polyps, or anatomical landmarks visible in the image?'}, {'role': 'assistant', 'content': 'Evidence of oesophagitis is present with no polyps identified and the z-line is visible.'}]\nimages: ['Kvasir-VQA-x1/images/clb0kvxvm90y4074yf50vf5nq.jpg']\n\n--- Sample 2 ---\nmessages: [{'role': 'user', 'content': '<image>What procedure is depicted in the image and what type of polyp is observed?'}, {'role': 'assistant', 'content': 'Evidence of a colonoscopy with a paris iia polyp noted'}]\nimages: ['Kvasir-VQA-x1/images/cl8k2u1r71foz083278j63qnm.jpg']\n\n--- Sample 3 ---\nmessages: [{'role': 'user', 'content': '<image>Have all polyps been removed, is there any text present, and where is the abnormality located in the image?'}, {'role': 'assistant', 'content': 'Polyps remain present, text is visible, and the abnormality is located in the central and upper-center regions.'}]\nimages: ['Kvasir-VQA-x1/images/cl8k2u1qa1ekz08324rek2qcv.jpg']\n\nLooks good ✅\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Count records in JSONL files\ndef count_records_in_jsonl(jsonl_file):\n    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n        return sum(1 for _ in f)\n\n# Get the count of records in train and test datasets\ntrain_records = count_records_in_jsonl(train_jsonl)\ntest_records = count_records_in_jsonl(test_jsonl)\n\nprint(f\"Number of records in the train dataset: {train_records}\")\nprint(f\"Number of records in the test dataset: {test_records}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:20:44.177596Z","iopub.execute_input":"2025-10-19T13:20:44.178047Z","iopub.status.idle":"2025-10-19T13:20:44.228605Z","shell.execute_reply.started":"2025-10-19T13:20:44.178005Z","shell.execute_reply":"2025-10-19T13:20:44.228027Z"}},"outputs":[{"name":"stdout","text":"Number of records in the train dataset: 143594\nNumber of records in the test dataset: 15955\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Reducing training and validation time\n!shuf -n 3000 Kvasir-VQA-x1/Kvasir-VQA-x1-train.jsonl > Kvasir-VQA-x1/Kvasir-VQA-x1-train-3000.jsonl\nTRN_3000_PATH = \"Kvasir-VQA-x1/Kvasir-VQA-x1-train-3000.jsonl\"\n\n!shuf -n 500 Kvasir-VQA-x1/Kvasir-VQA-x1-test.jsonl > Kvasir-VQA-x1/Kvasir-VQA-x1-test-500.jsonl\nVAL_500_PATH = \"Kvasir-VQA-x1/Kvasir-VQA-x1-test-500.jsonl\"\n\nMODEL_NAME = \"google/paligemma-3b-pt-224\"\nHUB_MODEL_ID = f\"Kvasir-VQA-x1-lora_{datetime.now().strftime('%y%m%d-%H%M')}\"\n\nTRAIN_PATH = str(TRN_3000_PATH)\nVAL_PATH = str(VAL_500_PATH)  # Use sampled validation set\n\nprint(\"Model:      \", MODEL_NAME)\nprint(\"Train file: \", TRAIN_PATH)\nprint(\"Valid file: \", VAL_PATH)\nprint(\"Hub repo:   \", HUB_MODEL_ID)\n\nprint(\"📝 You can find training logs after the training starts at: https://wandb.ai/home\")\nprint(\"📌 After each validation stage, the HF repository will be updated with the best model.\")\nprint(f\"✅ Model will be available at: https://huggingface.co/{HF_USER}/{HUB_MODEL_ID}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:21:21.739479Z","iopub.execute_input":"2025-10-19T13:21:21.739965Z","iopub.status.idle":"2025-10-19T13:21:22.176826Z","shell.execute_reply.started":"2025-10-19T13:21:21.739944Z","shell.execute_reply":"2025-10-19T13:21:22.176004Z"}},"outputs":[{"name":"stdout","text":"Model:       google/paligemma-3b-pt-224\nTrain file:  Kvasir-VQA-x1/Kvasir-VQA-x1-train-3000.jsonl\nValid file:  Kvasir-VQA-x1/Kvasir-VQA-x1-test-500.jsonl\nHub repo:    Kvasir-VQA-x1-lora_251019-1321\n📝 You can find training logs after the training starts at: https://wandb.ai/home\n📌 After each validation stage, the HF repository will be updated with the best model.\n✅ Model will be available at: https://huggingface.co/Firoj112/Kvasir-VQA-x1-lora_251019-1321\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Count records in the shuffled train and validation datasets\ntrain_shuffled_records = count_records_in_jsonl(TRN_3000_PATH)\nval_shuffled_records = count_records_in_jsonl(VAL_500_PATH)\n\n# Print the results\nprint(f\"Number of records in the shuffled train dataset: {train_shuffled_records}\")\nprint(f\"Number of records in the shuffled validation dataset: {val_shuffled_records}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:21:27.320709Z","iopub.execute_input":"2025-10-19T13:21:27.321543Z","iopub.status.idle":"2025-10-19T13:21:27.328287Z","shell.execute_reply.started":"2025-10-19T13:21:27.321513Z","shell.execute_reply":"2025-10-19T13:21:27.327512Z"}},"outputs":[{"name":"stdout","text":"Number of records in the shuffled train dataset: 3000\nNumber of records in the shuffled validation dataset: 500\n","output_type":"stream"}],"execution_count":10}]}